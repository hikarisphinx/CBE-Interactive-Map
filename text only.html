<!DOCTYPE html>
<html>
<head>
    <title>Misamis Oriental Project Management System</title>
    <link rel="stylesheet" href="style.css">
</head>
    <body>     
        <div class="container">
            <div class="row">
                <div class="map-div">
                    Information technology (IT) is the use of computers to create, process, store, retrieve and exchange all kinds of
                    data[1] and information. IT forms part of information and communications technology (ICT).[2] An information technology
                    system (IT system) is generally an information system, a communications system, or, more specifically speaking, a
                    computer system — including all hardware, software, and peripheral equipment — operated by a limited group of IT users,
                    and an IT project usually refers to the commissioning and implementation of an IT system.[3]
                    
                    Although humans have been storing, retrieving, manipulating, and communicating information since the earliest writing
                    systems were developed,[4] the term information technology in its modern sense first appeared in a 1958 article
                    published in the Harvard Business Review; authors Harold J. Leavitt and Thomas L. Whisler commented that "the new
                    technology does not yet have a single established name. We shall call it information technology (IT)."[5] Their
                    definition consists of three categories: techniques for processing, the application of statistical and mathematical
                    methods to decision-making, and the simulation of higher-order thinking through computer programs.[5]
                    
                    The term is commonly used as a synonym for computers and computer networks, but it also encompasses other information
                    distribution technologies such as television and telephones. Several products or services within an economy are
                    associated with information technology, including computer hardware, software, electronics, semiconductors, internet,
                    telecom equipment, and e-commerce.[6][a]
                    
                    Based on the storage and processing technologies employed, it is possible to distinguish four distinct phases of IT
                    development: pre-mechanical (3000 BC — 1450 AD), mechanical (1450—1840), electromechanical (1840—1940), and electronic
                    (1940 to present).[4]
                    
                    Information technology is also a branch of computer science, which can be defined as the overall study of procedure,
                    structure, and the processing of various types of data. As this field continues to evolve across the world, the overall
                    priority and importance has also grown, which is where we begin to see the introduction of computer science-related
                    courses in K-12 education.
                    
                    History
                    
                    Zuse Z3 replica on display at Deutsches Museum in Munich. The Zuse Z3 is the first programmable computer.
                    Main article: History of computing hardware
                    
                    This is the Antikythera mechanism, which is considered the first mechanical analog computer, dating back to the first
                    century BC.
                    Ideas of computer science were first mentioned before the 1950s under the Massachusetts Institute of Technology (MIT)
                    and Harvard University, where they had discussed and began thinking of computer circuits and numerical calculations. As
                    time went on, the field of information technology and computer science became more complex and was able to handle the
                    processing of more data. Scholarly articles began to be published from different organizations.[8]
                    
                    Looking at early computing, Alan Turing, J. Presper Eckert, and John Mauchly were considered to be some of the major
                    pioneers of computer technology in the mid-1900s. Giving them such credit for their developments, most of their efforts
                    were focused on designing the first digital computer. Along with that, topics such as artificial intelligence began to
                    be brought up as Turing was beginning to question such technology of the time period.[9]
                    
                    Devices have been used to aid computation for thousands of years, probably initially in the form of a tally stick.[10]
                    The Antikythera mechanism, dating from about the beginning of the first century BC, is generally considered to be the
                    earliest known mechanical analog computer, and the earliest known geared mechanism.[11] Comparable geared devices did
                    not emerge in Europe until the 16th century, and it was not until 1645 that the first mechanical calculator capable of
                    performing the four basic arithmetical operations was developed.[12]
                    
                    Electronic computers, using either relays or valves, began to appear in the early 1940s. The electromechanical Zuse Z3,
                    completed in 1941, was the world's first programmable computer, and by modern standards one of the first machines that
                    could be considered a complete computing machine. During the Second World War, Colossus developed the first electronic
                    digital computer to decrypt German messages. Although it was programmable, it was not general-purpose, being designed to
                    perform only a single task. It also lacked the ability to store its program in memory; programming was carried out using
                    plugs and switches to alter the internal wiring.[13] The first recognizably modern electronic digital stored-program
                    computer was the Manchester Baby, which ran its first program on 21 June 1948.[14]
                    
                    The development of transistors in the late 1940s at Bell Laboratories allowed a new generation of computers to be
                    designed with greatly reduced power consumption. The first commercially available stored-program computer, the Ferranti
                    Mark I, contained 4050 valves and had a power consumption of 25 kilowatts. By comparison, the first transistorized
                    computer developed at the University of Manchester and operational by November 1953, consumed only 150 watts in its
                    final version.[15]
                    
                    A Luddite Analysis. Norwood, NJ: Ablex. <br><br>
                </div>
                <div class="data-div">
                    Information technology (IT) is the use of computers to create, process, store, retrieve and exchange all kinds of
                    data[1] and information. IT forms part of information and communications technology (ICT).[2] An information technology
                    system (IT system) is generally an information system, a communications system, or, more specifically speaking, a
                    computer system — including all hardware, software, and peripheral equipment — operated by a limited group of IT users,
                    and an IT project usually refers to the commissioning and implementation of an IT system.[3]
                    
                    Although humans have been storing, retrieving, manipulating, and communicating information since the earliest writing
                    systems were developed,[4] the term information technology in its modern sense first appeared in a 1958 article
                    published in the Harvard Business Review; authors Harold J. Leavitt and Thomas L. Whisler commented that "the new
                    technology does not yet have a single established name. We shall call it information technology (IT)."[5] Their
                    definition consists of three categories: techniques for processing, the application of statistical and mathematical
                    methods to decision-making, and the simulation of higher-order thinking through computer programs.[5]
                    
                    The term is commonly used as a synonym for computers and computer networks, but it also encompasses other information
                    distribution technologies such as television and telephones. Several products or services within an economy are
                    associated with information technology, including computer hardware, software, electronics, semiconductors, internet,
                    telecom equipment, and e-commerce.[6][a]
                    
                    Based on the storage and processing technologies employed, it is possible to distinguish four distinct phases of IT
                    development: pre-mechanical (3000 BC — 1450 AD), mechanical (1450—1840), electromechanical (1840—1940), and electronic
                    (1940 to present).[4]
                    
                    Information technology is also a branch of computer science, which can be defined as the overall study of procedure,
                    structure, and the processing of various types of data. As this field continues to evolve across the world, the overall
                    priority and importance has also grown, which is where we begin to see the introduction of computer science-related
                    courses in K-12 education.
                    
                    History
                    
                    Zuse Z3 replica on display at Deutsches Museum in Munich. The Zuse Z3 is the first programmable computer.
                    Main article: History of computing hardware
                    
                    This is the Antikythera mechanism, which is considered the first mechanical analog computer, dating back to the first
                    century BC.
                    Ideas of computer science were first mentioned before the 1950s under the Massachusetts Institute of Technology (MIT)
                    and Harvard University, where they had discussed and began thinking of computer circuits and numerical calculations. As
                    time went on, the field of information technology and computer science became more complex and was able to handle the
                    processing of more data. Scholarly articles began to be published from different organizations.[8]
                    
                    Looking at early computing, Alan Turing, J. Presper Eckert, and John Mauchly were considered to be some of the major
                    pioneers of computer technology in the mid-1900s. Giving them such credit for their developments, most of their efforts
                    were focused on designing the first digital computer. Along with that, topics such as artificial intelligence began to
                    be brought up as Turing was beginning to question such technology of the time period.[9]
                    
                    Devices have been used to aid computation for thousands of years, probably initially in the form of a tally stick.[10]
                    The Antikythera mechanism, dating from about the beginning of the first century BC, is generally considered to be the
                    earliest known mechanical analog computer, and the earliest known geared mechanism.[11] Comparable geared devices did
                    not emerge in Europe until the 16th century, and it was not until 1645 that the first mechanical calculator capable of
                    performing the four basic arithmetical operations was developed.[12]
                    
                    Electronic computers, using either relays or valves, began to appear in the early 1940s. The electromechanical Zuse Z3,
                    completed in 1941, was the world's first programmable computer, and by modern standards one of the first machines that
                    could be considered a complete computing machine. During the Second World War, Colossus developed the first electronic
                    digital computer to decrypt German messages. Although it was programmable, it was not general-purpose, being designed to
                    perform only a single task. It also lacked the ability to store its program in memory; programming was carried out using
                    plugs and switches to alter the internal wiring.[13] The first recognizably modern electronic digital stored-program
                    computer was the Manchester Baby, which ran its first program on 21 June 1948.[14]
                    
                    The development of transistors in the late 1940s at Bell Laboratories allowed a new generation of computers to be
                    designed with greatly reduced power consumption. The first commercially available stored-program computer, the Ferranti
                    Mark I, contained 4050 valves and had a power consumption of 25 kilowatts. By comparison, the first transistorized
                    computer developed at the University of Manchester and operational by November 1953, consumed only 150 watts in its
                    final version.[15]
                    
                    A Luddite Analysis. Norwood, NJ: Ablex.
                </div>
            </div>
        </div>
    </body>
</html>